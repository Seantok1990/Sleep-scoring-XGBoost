# Sleep State Classifier using XGBoost
This code written in R allows for the analysis of sleep states in files generated from Pinnacle Technologies using their EEG/EMG system and Sirenia Software. The scoring algorithm is based on the application of eXtreme Gradient Boosted (XGBoost) 
using its implementation in R.

# Dependencies
The code requires several public libraries in R which can be easily downloaded using this script:
install.packages(c('tidyverse','xgboost','caret','mixtools'))

# Usage
Using Sirenia Sleep Software, perform your power calculations and your scoring of a Training Set and Test Set for the training of the model. It is recommended to have around 20 recording sessions of at least 1 hour each. Once all the scoring is done,
export all the files using the export "Power + Scores to TSV' from the menu in Sirenia Sleep:

![image](https://github.com/Seantok1990/Sleep-scoring-XGBoost/assets/159004287/e8d4d142-054b-404a-b071-0479f7bb11b1)

Split the tsv files into a test and training folder. It is recommended to have a 60-40 training test split.
Run the code with the necessary modifications to the script to change the folder where your data is stored.

Functions:
pre_process(input_file)
This function reads in *.tsv files that contain the power data and sleep scoring data (refer to example_power_scores.tsv for an example) and calculates the features for each electrode,
including relative power and removing NAs from the data file. This function returns a dataframe in R with all the features calculated.

estimate_error=function(input_file,model,softprob)
This function accepts a *.tsv file containing scores as an input with a trained XGBoost model, along with a a softprobability value output for diagnostics. This function 
assess the predictive behavior of the trained model on naive datasets. It will generate an accuracy score (Total correct/Total) as a measurement of the model error. This is used for 
diagnosing if the model is overfit or not.

predict_file=function(input_file,model,features,softprob)
This function predicts the labels for a single tsv file. It accepts input_file as the name of the tsv file, model as the trained XGBoost model, features as a list of features generated by the training process and the softprobability values for each class.

create_dense_mat=function (data)
Creates a dense matrix for the purposes of training in XGBoost.

# Features
Data Preprocessing: The data preprocessing steps involve reading, cleaning, calculations on the dataset and feature engineering to prepare the data for training.

Model Training: XGBoost is used to train the classification model on the preprocessed sleep data.

Model Evaluation: The trained model can be evaluated using various metrics such as accuracy, precision, recall, and F1-score to assess its performance. The default metric is mlogloss for multiclass classification

Model Deployment: Once the model is trained and evaluated, it saves the model as an .model file, and the feature list as a .features file.

License
This project is licensed under the MIT License.

Feel free to customize and expand upon this template to better suit your project's needs!
